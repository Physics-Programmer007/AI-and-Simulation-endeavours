{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8c4cee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\bismark\\Anaconda3 2\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "from scipy.interpolate import griddata\n",
    "import time\n",
    "from itertools import product, combinations\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from tensorflow.python.ops import random_ops\n",
    "import warnings\n",
    "from numba import jit\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ae2351b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(12345)\n",
    "tf.random.set_seed(12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d6ea2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhysicsInformedNN:\n",
    "    def __init__(self, x, t, p, n, q, G_L, R_n, R_p, J_n, J_p, layers):\n",
    "        X = np.concatenate([x, t, p, n], 1)\n",
    "        self.lb = X.min(0)\n",
    "        self.ub = X.max(0)\n",
    "        \n",
    "        self.X = X\n",
    "        self.x = X[:, 0:1]\n",
    "        self.t = X[:, 1:2]\n",
    "        self.p = X[:, 2:3]\n",
    "        self.n = X[:, 3:4]\n",
    "        \n",
    "        self.G_L = G_L\n",
    "        self.R_n = R_n\n",
    "        self.R_p = R_p\n",
    "        \n",
    "        self.layers = layers\n",
    "        self.J_n = J_n\n",
    "        self.J_p = J_p\n",
    "        self.q = q\n",
    "    \n",
    "        self.weights, self.biases = self.initialize_NN(layers)\n",
    "        \n",
    "        self.lambda_1 = tf.Variable([0.0], dtype=tf.float32)\n",
    "        \n",
    "        self.G_L = tf.Variable([G_L], dtype=tf.float32)\n",
    "        self.R_n = tf.Variable([R_n], dtype=tf.float32)\n",
    "        \n",
    "        self.sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(allow_soft_placement=True, log_device_placement=True))\n",
    "        \n",
    "        self.x_tf = tf.placeholder(tf.float32, shape=[None, self.x.shape[1]])\n",
    "        self.t_tf = tf.placeholder(tf.float32, shape=[None, self.t.shape[1]])\n",
    "        self.p_tf = tf.placeholder(tf.float32, shape=[None, self.p.shape[1]])\n",
    "        self.n_tf = tf.placeholder(tf.float32, shape=[None, self.n.shape[1]])\n",
    "        self.J_p_tf = tf.placeholder(tf.float32, shape=[None, self.J_p.shape[1]])\n",
    "        self.J_n_tf = tf.placeholder(tf.float32, shape=[None, self.J_n.shape[1]])\n",
    "        self.p_pred, self.n_pred, self.J_n_pred, self.J_p_pred, self.f_n_pred, self.f_p_pred = self.net_NS(self.x_tf, self.t_tf,\n",
    "                                                                                                           self.n_tf, self.p_tf, self.J_n_tf, \n",
    "                                                                                                           self.J_p_tf)\n",
    "        \n",
    "        self.loss = tf.reduce_sum(tf.square(self.p_tf - self.p_pred)) + \\\n",
    "                    tf.reduce_sum(tf.square(self.n_tf - self.n_pred)) + \\\n",
    "                    tf.reduce_sum(tf.square(self.J_p_tf-self.J_p_pred)) +\\\n",
    "                    tf.reduce_sum(tf.square(self.J_n_tf-self.J_n_pred)) +\\\n",
    "                    tf.reduce_sum(tf.square(self.f_n_pred)) + \\\n",
    "                    tf.reduce_sum(tf.square(self.f_p_pred))\n",
    "                    \n",
    "        self.optimizer_Adam = tf.compat.v1.train.AdamOptimizer()\n",
    "        self.train_op_Adam = self.optimizer_Adam.minimize(self.loss)\n",
    "        \n",
    "        init = tf.compat.v1.global_variables_initializer()\n",
    "        self.sess.run(init)\n",
    "        \n",
    "    def initialize_NN(self, layers):\n",
    "        weights = []\n",
    "        biases = []\n",
    "        num_layers = len(layers)\n",
    "        for l in range(0, num_layers-1):\n",
    "            W = self.xavier_init(size=[layers[l], layers[l+1]])\n",
    "            b = tf.Variable(tf.zeros([1, layers[l+1]]), dtype=tf.float32)  # Corrected shape of bias\n",
    "            weights.append(W)\n",
    "            biases.append(b)\n",
    "        return weights, biases\n",
    "    \n",
    "    def xavier_init(self, size):\n",
    "        in_dim = size[0]\n",
    "        out_dim = size[1]\n",
    "        xavier_stddev = np.sqrt(2/(in_dim + out_dim))\n",
    "        return tf.Variable(tf.random.truncated_normal([in_dim, out_dim], stddev=xavier_stddev), dtype=tf.float32)\n",
    "\n",
    "    \n",
    "    def neural_net(self, X, weights, biases):\n",
    "        num_layers = len(weights) + 1\n",
    "        H = 2.0 * (X - self.lb) / (self.ub - self.lb) - 1.0\n",
    "        for l in range(0, num_layers-2):\n",
    "            W = weights[l]\n",
    "            b = biases[l]\n",
    "            H = tf.tanh(tf.add(tf.matmul(H, W), b))\n",
    "        W = weights[-1]\n",
    "        b = biases[-1]\n",
    "        Y = tf.add(tf.matmul(H, W), b)\n",
    "        return Y\n",
    "    \n",
    "    def net_NS(self, x, t, n, p, J_n_input, J_p_input):\n",
    "        \n",
    "        lambda_1 = self.lambda_1\n",
    "    \n",
    "        f_pass = self.neural_net(tf.concat([x, t, n, p, J_n_input, J_p_input], 1), self.weights, self.biases)\n",
    "    \n",
    "        del_P = f_pass[:, 3:4]\n",
    "        del_n = f_pass[:, 2:3]\n",
    "        J_n_output = f_pass[:, 4:5]\n",
    "        J_p_output = f_pass[:, 5:6]\n",
    "    \n",
    "        del_p_t = tf.gradients(del_P, t)[0]\n",
    "        del_n_t = tf.gradients(del_n, t)[0]\n",
    "        del_J_n = tf.gradients(J_n_output, x)[0]\n",
    "        del_J_p = tf.gradients(J_p_output, x)[0]\n",
    "    \n",
    "        f_n = del_n_t - lambda_1 * (del_J_n / self.q) + self.R_n - self.G_L\n",
    "        f_p = del_p_t - lambda_1 * (del_J_p / self.q) + self.R_p - self.G_L\n",
    "    \n",
    "        return del_p_t, del_n_t, del_J_n, del_J_p, f_n, f_p\n",
    "\n",
    "    \n",
    "    def callback(self, loss, lambda_1):\n",
    "        print('Loss: %.3e, Lambda 1: %.3f' % (loss, lambda_1))\n",
    "    @jit\n",
    "    def train(self, nIter):\n",
    "        tf_dict = {self.x_tf: self.x, self.t_tf: self.t, self.p_tf: self.p, self.n_tf: self.n, self.J_p_tf: self.J_p, self.J_n_tf: self.J_n}\n",
    "        \n",
    "        start_time = time.time()\n",
    "        for it in range(nIter):\n",
    "            self.sess.run(self.train_op_Adam, tf_dict)\n",
    "            \n",
    "            if it % 10 == 0:\n",
    "                elapsed = time.time() - start_time\n",
    "                loss_value = self.sess.run(self.loss, tf_dict)\n",
    "                lambda_1_value = self.sess.run(self.lambda_1)\n",
    "                print('It: %d, Loss: %.3e, Lambda 1: %.3f, Time: %.2f' % (it, loss_value, lambda_1_value, elapsed))\n",
    "                start_time = time.time()\n",
    "                \n",
    "    def predict(self, x_star, t_star, p_star, n_star, J_p_star, J_n_star):\n",
    "        tf_dict = {self.x_tf: x_star, self.t_tf: t_star, self.n_tf: n_star, self.p_tf: p_star, self.J_p_tf: J_p_star, self.J_n_tf: J_n_star}\n",
    "        \n",
    "        p_pred = self.sess.run(self.p_pred, tf_dict)\n",
    "        n_pred = self.sess.run(self.n_pred, tf_dict)\n",
    "        J_n_pred = self.sess.run(self.J_n_pred, tf_dict)\n",
    "        J_p_pred = self.sess.run(self.J_p_pred, tf_dict)\n",
    "        \n",
    "        return p_pred, n_pred, J_n_pred, J_p_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe68e3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_solution(X_star, u_star, index):\n",
    "    # Assuming X_star has shape (num_points, 2) where each row is (x, t)\n",
    "    # Assuming u_star has shape (num_points, 4) where each row is (p, n, J_n, J_p)\n",
    "    \n",
    "    lb = X_star.min(0)\n",
    "    ub = X_star.max(0)\n",
    "    nn = 200\n",
    "    x = np.linspace(lb[0], ub[0], nn)\n",
    "    t = np.linspace(lb[1], ub[1], nn)\n",
    "    X, T = np.meshgrid(x, t)\n",
    "    \n",
    "    # Interpolate the solution values\n",
    "    U_star_p = griddata(X_star, u_star[:,0], (X, T), method='cubic')\n",
    "    U_star_n = griddata(X_star, u_star[:,1], (X, T), method='cubic')\n",
    "    U_star_Jn = griddata(X_star, u_star[:,2], (X, T), method='cubic')\n",
    "    U_star_Jp = griddata(X_star, u_star[:,3], (X, T), method='cubic')\n",
    "    \n",
    "    fig = plt.figure(index)\n",
    "    \n",
    "    ax1 = fig.add_subplot(221, projection='3d')\n",
    "    ax1.plot_surface(X, T, U_star_p, cmap='viridis')\n",
    "    ax1.set_title('p(x,t)')\n",
    "    ax1.set_xlabel('x')\n",
    "    ax1.set_ylabel('t')\n",
    "    ax1.set_zlabel('p')\n",
    "    axisEqual3D(ax1)\n",
    "    \n",
    "    ax2 = fig.add_subplot(222, projection='3d')\n",
    "    ax2.plot_surface(X, T, U_star_n, cmap='viridis')\n",
    "    ax2.set_title('n(x,t)')\n",
    "    ax2.set_xlabel('x')\n",
    "    ax2.set_ylabel('t')\n",
    "    ax2.set_zlabel('n')\n",
    "    axisEqual3D(ax2)\n",
    "    \n",
    "    ax3 = fig.add_subplot(223, projection='3d')\n",
    "    ax3.plot_surface(X, T, U_star_Jn, cmap='viridis')\n",
    "    ax3.set_title('J_n(x,t)')\n",
    "    ax3.set_xlabel('x')\n",
    "    ax3.set_ylabel('t')\n",
    "    ax3.set_zlabel('J_n')\n",
    "    axisEqual3D(ax3)\n",
    "    \n",
    "    ax4 = fig.add_subplot(224, projection='3d')\n",
    "    ax4.plot_surface(X, T, U_star_Jp, cmap='viridis')\n",
    "    ax4.set_title('J_p(x,t)')\n",
    "    ax4.set_xlabel('x')\n",
    "    ax4.set_ylabel('t')\n",
    "    ax4.set_zlabel('J_p')\n",
    "    axisEqual3D(ax4)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def axisEqual3D(ax):\n",
    "    extents = np.array([getattr(ax, 'get_{}lim'.format(dim))() for dim in 'xyz'])\n",
    "    sz = extents[:,1] - extents[:,0]\n",
    "    centers = np.mean(extents, axis=1)\n",
    "    maxsize = max(abs(sz))\n",
    "    r = maxsize/4\n",
    "    for ctr, dim in zip(centers, 'xyz'):\n",
    "        getattr(ax, 'set_{}lim'.format(dim))(ctr - r, ctr + r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7bd375",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
